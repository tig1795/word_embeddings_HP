{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klassifizierung von Nachrichtensendungen: ein Beispiel für die Klassifizierung mehrerer Klassen\n",
    "\n",
    "Dieses Notizbuch enthält die Codebeispiele aus Kapitel 3, Abschnitt 5 von Deep Learning mit Python. Beachten Sie, dass der Originaltext weitaus mehr Inhalt aufweist, insbesondere weitere Erklärungen und Abbildungen: In diesem Notizbuch finden Sie nur Quellcode und zugehörige Kommentare.\n",
    "\n",
    "Im vorigen Abschnitt haben wir gesehen, wie Vektoreingaben mithilfe eines dicht verknüpften neuronalen Netzes in zwei sich gegenseitig ausschließende Klassen klassifiziert werden können. Aber was passiert, wenn Sie mehr als zwei Klassen haben?\n",
    "\n",
    "In diesem Abschnitt werden wir ein Netzwerk erstellen, um Reuters-Nachrichten in 46 verschiedene, sich gegenseitig ausschließende Themen zu klassifizieren. Da wir viele Klassen haben, ist dieses Problem ein Fall von \"Mehrklassen-Klassifikation\", und da jeder Datenpunkt nur einer Kategorie zugeordnet werden sollte, ist das Problem genauer gesagt ein Fall von \"Ein-Label-Mehrklassen-Klassifikation\". Wenn jeder Datenpunkt zu mehreren Kategorien (in unserem Fall Themen) gehören könnte, hätten wir es mit einem \"Multi-Label, Multi-Class-Klassifikation\"-Problem zu tun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Der Reuters-Datensatz\n",
    "\n",
    "Wir werden mit dem Reuters-Datensatz arbeiten, einem Satz von Kurznachrichten und deren Themen, der 1986 von Reuters veröffentlicht wurde. Es ist ein sehr einfacher, weit verbreiteter Spielzeugdatensatz für die Textklassifikation. Es gibt 46 verschiedene Themen; einige Themen sind stärker vertreten als andere, aber jedes Thema hat mindestens 10 Beispiele in der Trainingsmenge.\n",
    "\n",
    "Wie IMDB und MNIST wird auch der Reuters-Datensatz als Teil von Keras ausgeliefert. Werfen wir gleich einen Blick darauf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie beim IMDB-Datensatz schränkt das Argument num_words=10000 die Daten auf die 10.000 am häufigsten vorkommenden Wörter ein, die in den Daten gefunden wurden.\n",
    "\n",
    "Wir haben 8.982 Trainingsbeispiele und 2.246 Testbeispiele:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8982"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2246"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie bei den IMDB-Reviews ist jedes Beispiel eine Liste von Ganzzahlen (Wortindizes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 245,\n",
       " 273,\n",
       " 207,\n",
       " 156,\n",
       " 53,\n",
       " 74,\n",
       " 160,\n",
       " 26,\n",
       " 14,\n",
       " 46,\n",
       " 296,\n",
       " 26,\n",
       " 39,\n",
       " 74,\n",
       " 2979,\n",
       " 3554,\n",
       " 14,\n",
       " 46,\n",
       " 4689,\n",
       " 4329,\n",
       " 86,\n",
       " 61,\n",
       " 3499,\n",
       " 4795,\n",
       " 14,\n",
       " 61,\n",
       " 451,\n",
       " 4329,\n",
       " 17,\n",
       " 12]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Falls Sie neugierig sind, hier ist, wie Sie es wieder in Worte entschlüsseln können:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
      "557056/550378 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "# Beachten Sie, dass unsere Indizes um 3 versetzt wurden\n",
    "# weil 0, 1 und 2 reservierte Indizes für \"padding\", \"start of sequence\" und \"unknown\" sind.\n",
    "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_newswire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die einem Beispiel zugeordnete Bezeichnung ist eine ganze Zahl zwischen 0 und 45: ein Themenindex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vorbereiten der Daten\n",
    "\n",
    "Wir können die Daten mit genau demselben Code wie in unserem vorherigen Beispiel vektorisieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "# Unsere vektorisierten Trainingsdaten\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# Unsere vektorisierten Testdaten\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Beschriftungen zu vektorisieren, gibt es zwei Möglichkeiten: Wir könnten die Beschriftungsliste einfach als Integer-Tensor darstellen, oder wir könnten eine \"One-Hot\"-Kodierung verwenden. Die One-Hot-Kodierung ist ein weit verbreitetes Format für kategoriale Daten, auch \"kategoriale Kodierung\" genannt. Eine genauere Erklärung der One-Hot-Kodierung finden Sie in Kapitel 6, Abschnitt 1. In unserem Fall besteht die One-Hot-Kodierung unserer Labels darin, dass jedes Label als All-Null-Vektor mit einer 1 an der Stelle des Label-Index eingebettet wird, z. B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "\n",
    "# Unsere vektorisierten Trainingsetiketten\n",
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "# Unsere vektorisierten Testetiketten\n",
    "one_hot_test_labels = to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beachten Sie, dass es eine eingebaute Möglichkeit gibt, dies in Keras zu tun, die Sie bereits in unserem MNIST-Beispiel in Aktion gesehen haben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufbau unseres Netzwerks\n",
    "\n",
    "Dieses Problem der Themenklassifikation sieht unserem vorherigen Problem der Filmkritik-Klassifikation sehr ähnlich: In beiden Fällen versuchen wir, kurze Textabschnitte zu klassifizieren. Allerdings gibt es hier eine neue Einschränkung: Die Anzahl der Ausgabeklassen ist von 2 auf 46 gestiegen, d. h. die Dimensionalität des Ausgaberaums ist viel größer.\n",
    "\n",
    "In einem Stapel von Dense-Schichten, wie wir ihn verwendet haben, kann jede Schicht nur auf Informationen zugreifen, die in der Ausgabe der vorherigen Schicht vorhanden sind. Wenn eine Schicht einige für das Klassifizierungsproblem relevante Informationen auslässt, können diese Informationen von späteren Schichten nie wiederhergestellt werden: Jede Schicht kann potenziell zu einem \"Informationsengpass\" werden. In unserem vorherigen Beispiel haben wir 16-dimensionale Zwischenschichten verwendet, aber ein 16-dimensionaler Raum kann zu begrenzt sein, um die Trennung von 46 verschiedenen Klassen zu lernen: solche kleinen Schichten können als Informationsengpässe wirken, da sie permanent relevante Informationen fallen lassen.\n",
    "\n",
    "Aus diesem Grund werden wir größere Schichten verwenden. Versuchen wir es mit 64 Einheiten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es gibt zwei weitere Dinge, die Sie bei dieser Architektur beachten sollten:\n",
    "\n",
    "- Wir beenden das Netzwerk mit einer Dense-Schicht der Größe 46. Das bedeutet, dass unser Netzwerk für jede Eingabeprobe einen 46-dimensionalen Vektor ausgibt. Jeder Eintrag in diesem Vektor (jede Dimension) wird eine andere Ausgabeklasse kodieren.\n",
    "\n",
    "- Die letzte Schicht verwendet eine Softmax-Aktivierung. Dieses Muster haben Sie bereits im MNIST-Beispiel gesehen. Es bedeutet, dass das Netzwerk eine Wahrscheinlichkeitsverteilung über die 46 verschiedenen Ausgabeklassen ausgibt, d. h. für jede Eingabeprobe erzeugt das Netzwerk einen 46-dimensionalen Ausgabevektor, wobei output[i] die Wahrscheinlichkeit ist, dass die Probe zur Klasse i gehört. Die 46 Werte summieren sich zu 1.\n",
    "\n",
    "Die beste Verlustfunktion, die in diesem Fall verwendet werden kann, ist categorical_crossentropy. Sie misst den Abstand zwischen zwei Wahrscheinlichkeitsverteilungen: in unserem Fall zwischen der Wahrscheinlichkeitsverteilung, die von unserem Netzwerk ausgegeben wird, und der wahren Verteilung der Labels. Indem wir den Abstand zwischen diesen beiden Verteilungen minimieren, trainieren wir unser Netzwerk so, dass es etwas ausgibt, das den wahren Bezeichnungen so nahe wie möglich kommt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validierung unseres Ansatzes\n",
    "\n",
    "Lassen Sie uns 1.000 Samples von unseren Trainingsdaten absondern, um sie als Validierungsset zu verwenden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lassen Sie uns nun unser Netzwerk für 20 Epochen trainieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 2.6804 - accuracy: 0.5109 - val_loss: 1.7610 - val_accuracy: 0.6470\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 1.4459 - accuracy: 0.7023 - val_loss: 1.3241 - val_accuracy: 0.7180\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 1.0810 - accuracy: 0.7711 - val_loss: 1.1842 - val_accuracy: 0.7410\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.8630 - accuracy: 0.8156 - val_loss: 1.0830 - val_accuracy: 0.7710\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.6947 - accuracy: 0.8568 - val_loss: 0.9974 - val_accuracy: 0.7970\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.5610 - accuracy: 0.8822 - val_loss: 0.9411 - val_accuracy: 0.8100\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.4529 - accuracy: 0.9058 - val_loss: 0.9390 - val_accuracy: 0.8090\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.3705 - accuracy: 0.9219 - val_loss: 0.9057 - val_accuracy: 0.8240\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.3032 - accuracy: 0.9347 - val_loss: 0.9097 - val_accuracy: 0.8160\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.2591 - accuracy: 0.9424 - val_loss: 0.9091 - val_accuracy: 0.8150\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.2156 - accuracy: 0.9469 - val_loss: 0.9333 - val_accuracy: 0.8150\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.1952 - accuracy: 0.9511 - val_loss: 0.9497 - val_accuracy: 0.8190\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.1711 - accuracy: 0.9515 - val_loss: 0.9375 - val_accuracy: 0.8160\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.1579 - accuracy: 0.9536 - val_loss: 1.0121 - val_accuracy: 0.8100\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.1427 - accuracy: 0.9569 - val_loss: 0.9869 - val_accuracy: 0.8180\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.1340 - accuracy: 0.9569 - val_loss: 0.9898 - val_accuracy: 0.8150\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.1282 - accuracy: 0.9551 - val_loss: 1.0107 - val_accuracy: 0.8130\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.1197 - accuracy: 0.9585 - val_loss: 1.0923 - val_accuracy: 0.8050\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.1173 - accuracy: 0.9562 - val_loss: 1.0597 - val_accuracy: 0.8130\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.1100 - accuracy: 0.9588 - val_loss: 1.1197 - val_accuracy: 0.8100\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lassen Sie sich seine Verlust- und Genauigkeitskurven anzeigen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de5xVZdn/8c8FjCIHAQFTQRhIfsrBAYYJMUnwEI9gapopCJqmkmal2UFSM/OJUjMl1DQttWIUSx/NDFNTiuyAAgKKSKCCIoQDyknAGLh+f9xrhs2wZ2YPs9fee2Z936/Xeu2112lfe82eda113+u+l7k7IiKSXC3yHYCIiOSXEoGISMIpEYiIJJwSgYhIwikRiIgknBKBiEjCKRFIVplZSzPbbGY9srlsPpnZYWaW9fuszexEM1ue8n6JmX0qk2X34rN+YWZX7+36dWz3B2b2QLa3K7nVKt8BSH6Z2eaUt22Aj4Ad0fsvuXt5Q7bn7juAdtleNgnc/fBsbMfMLgImuPvIlG1flI1tS/OkRJBw7l59II7OOC9y9z/XtryZtXL3ylzEJiK5oaIhqVN06f+wmT1kZpuACWZ2tJn9y8zWm9lqM5tqZkXR8q3MzM2sOHo/LZr/lJltMrN/mlmvhi4bzR9tZv82sw1mdruZ/d3Mzq8l7kxi/JKZLTOzD8xsasq6Lc3sNjNbZ2ZvACfVsX+uNbPpNabdaWa3RuMXmdni6Pu8EZ2t17atlWY2MhpvY2a/iWJbBAxJ87lvRttdZGanRtOPBO4APhUVu61N2bfXp6x/SfTd15nZ42Z2cCb7pj5m9tkonvVm9ryZHZ4y72ozW2VmG83s9ZTvOszM5kXT15jZjzP9PMkSd9egAXcHWA6cWGPaD4D/AqcQThz2Az4BHEW4ouwN/Bv4SrR8K8CB4uj9NGAtUAYUAQ8D0/Zi2QOBTcBp0bwrge3A+bV8l0xi/D3QASgG3q/67sBXgEVAd6AzMCv8q6T9nN7AZqBtyrbfA8qi96dEyxhwPLAVKInmnQgsT9nWSmBkNH4L8BegE9ATeK3GsmcBB0d/k3OiGD4WzbsI+EuNOKcB10fjo6IYBwGtgZ8Bz2eyb9J8/x8AD0TjfaM4jo/+RldH+70I6A+sAA6Klu0F9I7GXwLGRePtgaPy/b+QtEFXBJKJF9z9D+6+0923uvtL7j7b3Svd/U3gHmBEHes/4u5z3H07UE44ADV02c8A893999G82whJI60MY/yRu29w9+WEg27VZ50F3ObuK919HXBjHZ/zJvAqIUEBfBpY7+5zovl/cPc3PXgeeA5IWyFcw1nAD9z9A3dfQTjLT/3c37r76uhv8iAhiZdlsF2A8cAv3H2+u28DJgEjzKx7yjK17Zu6jAWecPfno7/RjcD+hIRcSUg6/aPixbeifQchofcxs87uvsndZ2f4PSRLlAgkE++kvjGzI8zsj2b2HzPbCNwAdKlj/f+kjG+h7gri2pY9JDUOd3fCGXRaGcaY0WcRzmTr8iAwLho/h5DAquL4jJnNNrP3zWw94Wy8rn1V5eC6YjCz881sQVQEsx44IsPtQvh+1dtz943AB0C3lGUa8jerbbs7CX+jbu6+BPgG4e/wXlTUeFC06AVAP2CJmb1oZmMy/B6SJUoEkomat07+nHAWfJi77w9cRyj6iNNqQlENAGZm7H7gqqkxMa4GDk15X9/trQ8DJ0Zn1KcREgNmth/wCPAjQrFNR+CZDOP4T20xmFlv4C7gUqBztN3XU7Zb362uqwjFTVXba08ogno3g7gast0WhL/ZuwDuPs3djyEUC7Uk7BfcfYm7jyUU//0EeNTMWjcyFmkAJQLZG+2BDcCHZtYX+FIOPvNJoNTMTjGzVsDlQNeYYvwtcIWZdTOzzsBVdS3s7muAF4D7gSXuvjSatS+wD1AB7DCzzwAnNCCGq82so4V2Fl9JmdeOcLCvIOTEiwhXBFXWAN2rKsfTeAi40MxKzGxfwgH5b+5e6xVWA2I+1cxGRp/9LUK9zmwz62tmx0WftzUadhC+wLlm1iW6gtgQfbedjYxFGkCJQPbGN4AvEP7Jf044I45VdLA9G7gVWAd8HHiZ0O4h2zHeRSjLf4VQkflIBus8SKj8fTAl5vXA14HHCBWuZxISWia+R7gyWQ48Bfw6ZbsLganAi9EyRwCp5erPAkuBNWaWWsRTtf6fCEU0j0Xr9yDUGzSKuy8i7PO7CEnqJODUqL5gX+BmQr3OfwhXINdGq44BFlu4K+0W4Gx3/29j45HMWShqFWlazKwloSjiTHf/W77jEWnKdEUgTYaZnWRmHaLihe8S7kR5Mc9hiTR5SgTSlAwH3iQUL5wEfNbdaysaEpEMqWhIRCThdEUgIpJwTa7TuS5dunhxcXG+wxARaVLmzp271t3T3nLd5BJBcXExc+bMyXcYIiJNipnV2kJeRUMiIgmnRCAiknBKBCIiCdfk6ghEJLe2b9/OypUr2bZtW75DkQy0bt2a7t27U1RUW1dTe1IiEJE6rVy5kvbt21NcXEzo9FUKlbuzbt06Vq5cSa9evepfIZKIoqHyciguhhYtwmt5gx7HLpJs27Zto3PnzkoCTYCZ0blz5wZfvTX7K4Lycpg4EbZsCe9XrAjvAcY3ur9FkWRQEmg69uZv1eyvCK65ZlcSqLJlS5guIiIJSARvv92w6SJSWNatW8egQYMYNGgQBx10EN26dat+/9//ZvbYggsuuIAlS5bUucydd95JeZbKjYcPH878+fOzsq1caPZFQz16hOKgdNNFJPvKy8MV99tvh/+zyZMbVwzbuXPn6oPq9ddfT7t27fjmN7+52zLujrvTokX6c9v777+/3s+57LLL9j7IJq7ZXxFMngxt2uw+rU2bMF1EsquqTm7FCnDfVScXxw0ay5YtY8CAAVxyySWUlpayevVqJk6cSFlZGf379+eGG26oXrbqDL2yspKOHTsyadIkBg4cyNFHH817770HwLXXXsuUKVOql580aRJDhw7l8MMP5x//+AcAH374IZ/73OcYOHAg48aNo6ysrN4z/2nTpnHkkUcyYMAArr76agAqKys599xzq6dPnToVgNtuu41+/foxcOBAJkyYkPV9VptmnwjGj4d77oGePcEsvN5zjyqKReKQ6zq51157jQsvvJCXX36Zbt26ceONNzJnzhwWLFjAs88+y2uvvbbHOhs2bGDEiBEsWLCAo48+mvvuuy/ttt2dF198kR//+MfVSeX222/noIMOYsGCBUyaNImXX365zvhWrlzJtddey8yZM3n55Zf5+9//zpNPPsncuXNZu3Ytr7zyCq+++irnnXceADfffDPz589nwYIF3HHHHY3cO5lr9okAwkF/+XLYuTO8KgmIxCPXdXIf//jH+cQnPlH9/qGHHqK0tJTS0lIWL16cNhHst99+jB49GoAhQ4awfPnytNs+44wz9ljmhRdeYOzYsQAMHDiQ/v371xnf7NmzOf744+nSpQtFRUWcc845zJo1i8MOO4wlS5Zw+eWX8/TTT9OhQwcA+vfvz4QJEygvL29Qg7DGSkQiEJHcqK3uLa46ubZt21aPL126lJ/+9Kc8//zzLFy4kJNOOint/fT77LNP9XjLli2prKxMu+199913j2Ua+iCv2pbv3LkzCxcuZPjw4UydOpUvfelLADz99NNccsklvPjii5SVlbFjx44Gfd7eUiIQkazJZ53cxo0bad++Pfvvvz+rV6/m6aefzvpnDB8+nN/+9rcAvPLKK2mvOFINGzaMmTNnsm7dOiorK5k+fTojRoygoqICd+fzn/883//+95k3bx47duxg5cqVHH/88fz4xz+moqKCLTXL2WLS7O8aEpHcqSp2zeZdQ5kqLS2lX79+DBgwgN69e3PMMcdk/TO++tWvct5551FSUkJpaSkDBgyoLtZJp3v37txwww2MHDkSd+eUU07h5JNPZt68eVx44YW4O2bGTTfdRGVlJeeccw6bNm1i586dXHXVVbRv3z7r3yGdJvfM4rKyMteDaURyZ/HixfTt2zffYRSEyspKKisrad26NUuXLmXUqFEsXbqUVq0K65w63d/MzOa6e1m65QsrehGRArZ582ZOOOEEKisrcXd+/vOfF1wS2BtN/xuIiORIx44dmTt3br7DyLrYKovN7FAzm2lmi81skZldnmaZkWa2wczmR8N1ccUjIiLpxXlFUAl8w93nmVl7YK6ZPevuNavZ/+bun4kxDhERqUNsVwTuvtrd50Xjm4DFQLe4Pk9ERPZOTtoRmFkxMBiYnWb20Wa2wMyeMrO0zfTMbKKZzTGzORUVFTFGKiKSPLEnAjNrBzwKXOHuG2vMngf0dPeBwO3A4+m24e73uHuZu5d17do13oBFpKCMHDlyj8ZhU6ZM4ctf/nKd67Vr1w6AVatWceaZZ9a67fpuR58yZcpuDbvGjBnD+vXrMwm9Ttdffz233HJLo7eTDbEmAjMrIiSBcnf/v5rz3X2ju2+OxmcARWbWJc6YRKRpGTduHNOnT99t2vTp0xk3blxG6x9yyCE88sgje/35NRPBjBkz6Nix415vrxDFedeQAb8EFrv7rbUsc1C0HGY2NIpnXVwxiUjTc+aZZ/Lkk0/y0UcfAbB8+XJWrVrF8OHDq+/rLy0t5cgjj+T3v//9HusvX76cAQMGALB161bGjh1LSUkJZ599Nlu3bq1e7tJLL63uwvp73/seAFOnTmXVqlUcd9xxHHfccQAUFxezdu1aAG699VYGDBjAgAEDqruwXr58OX379uXiiy+mf//+jBo1arfPSWf+/PkMGzaMkpISTj/9dD744IPqz+/Xrx8lJSXVnd399a9/rX4wz+DBg9m0adNe79sqcd41dAxwLvCKmVV12H010APA3e8GzgQuNbNKYCsw1ptaU2eRBLniCsj2g7cGDYLoGJpW586dGTp0KH/605847bTTmD59OmeffTZmRuvWrXnsscfYf//9Wbt2LcOGDePUU0+t9bm9d911F23atGHhwoUsXLiQ0tLS6nmTJ0/mgAMOYMeOHZxwwgksXLiQr33ta9x6663MnDmTLl12L6yYO3cu999/P7Nnz8bdOeqooxgxYgSdOnVi6dKlPPTQQ9x7772cddZZPProo3U+X+C8887j9ttvZ8SIEVx33XV8//vfZ8qUKdx444289dZb7LvvvtXFUbfccgt33nknxxxzDJs3b6Z169YN2NvpxXnX0Avubu5e4u6DomGGu98dJQHc/Q537+/uA919mLv/I654RKTpSi0eSi0WcneuvvpqSkpKOPHEE3n33XdZs2ZNrduZNWtW9QG5pKSEkpKS6nm//e1vKS0tZfDgwSxatKjeDuVeeOEFTj/9dNq2bUu7du0444wz+Nvf/gZAr169GDRoEFB3V9cQno+wfv16RowYAcAXvvAFZs2aVR3j+PHjmTZtWnUL5mOOOYYrr7ySqVOnsn79+qy0bFbLYhHJWF1n7nH67Gc/y5VXXsm8efPYunVr9Zl8eXk5FRUVzJ07l6KiIoqLi9N2PZ0q3dXCW2+9xS233MJLL71Ep06dOP/88+vdTl2FF1VdWEPoxrq+oqHa/PGPf2TWrFk88cQT/O///i+LFi1i0qRJnHzyycyYMYNhw4bx5z//mSOOOGKvtl9F3VCLSMFr164dI0eO5Itf/OJulcQbNmzgwAMPpKioiJkzZ7Ii3QPKUxx77LHVD6h/9dVXWbhwIRC6sG7bti0dOnRgzZo1PPXUU9XrtG/fPm05/LHHHsvjjz/Oli1b+PDDD3nsscf41Kc+1eDv1qFDBzp16lR9NfGb3/yGESNGsHPnTt555x2OO+44br75ZtavX8/mzZt54403OPLII7nqqqsoKyvj9ddfb/Bn1qQrAhFpEsaNG8cZZ5yx2x1E48eP55RTTqGsrIxBgwbVe2Z86aWXcsEFF1BSUsKgQYMYOnQoEJ42NnjwYPr3779HF9YTJ05k9OjRHHzwwcycObN6emlpKeeff371Ni666CIGDx5cZzFQbX71q19xySWXsGXLFnr37s3999/Pjh07mDBhAhs2bMDd+frXv07Hjh357ne/y8yZM2nZsiX9+vWrftpaY6gbahGpk7qhbnoa2g21ioZERBJOiUBEJOGUCESkXk2tCDnJ9uZvpUQgInVq3bo169atUzJoAtyddevWNbiRme4aEpE6de/enZUrV6Kef5uG1q1b07179wato0QgInUqKiqiV69e+Q5DYqSiIRGRhFMiEBFJOCUCEZGEUyIQEUk4JQIRkYRTIhARSTglAhGRhFMiEBFJOCUCEZGEUyIQEUk4JQIRkYRTIhARSTglAhGRhFMiEBFJOCUCEZGEUyIQEUk4JQIRkYRTIhARSTglAhGRhIstEZjZoWY208wWm9kiM7s8zTJmZlPNbJmZLTSz0rjiERGR9OJ8eH0l8A13n2dm7YG5Zvasu7+WssxooE80HAXcFb2KiEiOxHZF4O6r3X1eNL4JWAx0q7HYacCvPfgX0NHMDo4rJhER2VNO6gjMrBgYDMyuMasb8E7K+5XsmSxERCRGsScCM2sHPApc4e4ba85Os4qn2cZEM5tjZnMqKiriCFNEJLFiTQRmVkRIAuXu/n9pFlkJHJryvjuwquZC7n6Pu5e5e1nXrl3jCVZEJKHivGvIgF8Ci9391loWewI4L7p7aBiwwd1XxxWTiIjsKc67ho4BzgVeMbP50bSrgR4A7n43MAMYAywDtgAXxBiPiIikEVsicPcXSF8HkLqMA5fFFYOIiNRPLYtFRBJOiUBEJOGUCEREEk6JQEQk4ZQIREQSTolARCThlAhERBJOiUBEJOGUCEREEk6JQEQk4ZQIREQSLlGJwPd40oGIiCQmEfzpT3D44bB2bb4jEREpLIlJBD17wrJlMHVqviMRESksiUkEffvC6afD7bfDxpoPzBQRSbDEJAKA73wH1q+Hu+/OdyQiIoUjUYmgrAxGjYJbb4WtW/MdjYhIYUhUIgC4+mpYswbuuy/fkYiIFIbEJYJjj4VPfhJuvhm2b893NCIi+Ze4RGAWrgrefhsefDDf0YiI5F/iEgHAmDFQUgI/+hHs2JHvaERE8iuRiaDqqmDJEnj88XxHIyKSX4lMBABnngmHHQY//KG6nhCRZEtsImjZEiZNgnnz4Jln8h2NiEj+JDYRAJx7LnTvHq4KRESSKtGJYJ994Fvfglmz4IUX8h2NiEh+JDoRAFx0EXTpEu4gEhFJosQngjZt4OtfhxkzYP78fEcjIpJ7iU8EAF/+Muy/v64KRCSZlAiAjh3hssvgd7+Df/8739GIiORWbInAzO4zs/fM7NVa5o80sw1mNj8arosrlkxccQXsuy/cdFM+oxARyb04rwgeAE6qZ5m/ufugaLghxljqdeCBcPHF8Otfh36IRESSIrZE4O6zgPfj2n4cvvnN8PqTn+Q3DhGRXMooEZjZx81s32h8pJl9zcw6ZuHzjzazBWb2lJn1r+PzJ5rZHDObU1FRkYWPTa9Hj9DI7N574b33YvsYEZGCkukVwaPADjM7DPgl0AtobCfO84Ce7j4QuB2otfs3d7/H3cvcvaxr166N/Ni6XXUVbNsGU6bsmlZeDsXF0KJFeC0vjzUEEZGcyjQR7HT3SuB0YIq7fx04uDEf7O4b3X1zND4DKDKzLo3ZZjYcfnjokO7OO8PzjcvLYeJEWLEidE63YkV4r2QgIs1Fpolgu5mNA74APBlNK2rMB5vZQWZm0fjQKJZ1jdlmtnznO7BxI/zsZ3DNNbBly+7zt2wJ00VEmoNWGS53AXAJMNnd3zKzXsC0ulYws4eAkUAXM1sJfI8oebj73cCZwKVmVglsBca6F0aH0IMHw+jRcNttsHZt+mV0Z5GINBfW0GOvmXUCDnX3hfGEVLeysjKfM2dO7J/z97/D8OHQqRN88MGe83v2hOXLYw9DRCQrzGyuu5elm5fpXUN/MbP9zewAYAFwv5ndms0gC80xx4QH3ZvBfvvtPq9NG5g8OT9xiYhkW6Z1BB3cfSNwBnC/uw8BTowvrMJw9dXw/vswYUK4AjALr/fcA+PH5zs6EZHsyLSOoJWZHQycBSSmmnTUKCgthb/8Bd54IzzVTESkucn0iuAG4GngDXd/ycx6A0vjC6swVD3kfulSePTRfEcjIhKPBlcW51uuKour7NwJ/fuHDulefjkkBxGRpiYblcXdzeyxqDfRNWb2qJl1z26YhalFi/CQ+wUL4Kmn8h2NiEj2ZVo0dD/wBHAI0A34QzQtEc45J/RDNHlyaF0sItKcZJoIurr7/e5eGQ0PAPF2+lNAiopCH0T/+EfolO79JtWnqohI3TJNBGvNbIKZtYyGCRRIdxC58qUvwfXXw8MPhzqDP/wh3xGJiGRHpongi4RbR/8DrCZ0D3FBXEEVopYt4Xvfg5deCg+xOfVUOP/80DGdiEhTllEicPe33f1Ud+/q7ge6+2cJjcsSZ9CgkAy++12YNi1cHcyYke+oRET2XmOeUHZl1qJoYvbZB264AWbPDn0RnXwyXHghbNiQ78hERBquMYkg8XfUDxkCc+eGbqsfeAAGDIBnnsl3VCIiDdOYRKAbKQkNzX74Q/jnP6F9e/if/wkPrtm4Md+RiYhkps5EYGabzGxjmmEToU2BRIYOhXnz4Nvfhl/+Eo48Ep57Lt9RiYjUr85E4O7t3X3/NEN7d8+0w7rEaN0abroJXnghjJ94Inz5y7B5c74jExGpXWOKhqQWRx8N8+fDlVfC3XdDSUnowVREpBApEcRkv/3gJz+BWbNCG4TjjoOvfhXWJaoZnog0BUoEMRs+PHRYd/nlcOed4cE23/42rFmT78hERAIlghxo0wamTIFXXgktkn/yEyguDsnh3XfzHZ2IJJ0SQQ717w8PPgiLF8PYseEKoXdvuOQSWL4839GJSFIpEeTB//t/cP/9sGwZfPGLYbxPH7jggvA0NBGRXFIiyKPiYrjrrvA85Msug+nT4YgjwvMPFi3Kd3QiUiiWLoWpU8PNJ3FQIsiB8vJw0G/RIryWl+8+v3v3UIewfDl885vwxBOhu4rPfS48HlNEkmXbNnj66VCP2KdPKEW4/PL4ur/XM4tjVl4eupzYsmXXtDZt4J57YPz49OusWwc//Wk4A9iwAT7zGbj2WjjqqNzELCK7++gjePbZ0KXMEUeEk7dsP7/8rbfC43BnzIDnn4etW0PD1OOPhzFjYPToUKe4t+p6ZrESQcyKi2HFij2n9+xZfwXxhg1wxx1w220hOZx4YjgrGD06tE0QkXgtWhS6jPn1r3dvA9S2bUgINYc+fUKyyMRHH4VeCGbMCMPrr4fpvXuHHo3HjIERI0KbpGxQIsijFi3SP+fYDHbuzGwbmzeHFsq33gqrV4ckMnFi6Pr6Yx/LbrwiSffhh+FJhL/4RehMsqgITjst3Nix337hrr/XX981vP32rnVbtIBevXYlhr59d4137gzvvLPrrP/Pfw6ftc8+MHLkrrP+Pn2yf7UBSgR51Zgrgpq2bw/1Bz/7Wbh0LCqCM86ASy+FY4+N58cjkgTuoUv5e++Fhx6CTZvCwfuii8Jzyg88sPZ1P/wQ/v3v3ZPD66/DkiXhrL9Khw67nlnSs+euA//xx4crjLgpEeTR3tQRZGLJknCV8MAD4XGZ/fqFhHDuueEHJyL1++CD8D/6i1+EHgD22w/OOgsuvhg++cnGnVzt2BGuFl5/PVxFLF0Khx0WDv59++b+xK2uRIC7xzIA9wHvAa/WMt+AqcAyYCFQmsl2hwwZ4k3NtGnuPXu6m4XXadOyt+0PP3S/7z73T3zCHdzbtHG/+GL3efOy9xkizcnOne5/+Yv7hAnurVuH/5shQ9zvust9/fp8RxcfYI7XclyN7YrAzI4FNgO/dvcBaeaPAb4KjAGOAn7q7vXeF9PUrghyae7c0C7hwQfDHQdHHRWuEs46K3sVTpJM7uGMtnVrOOQQaNXEOqHfuTN05/LQQ+Hsf+nScOU8fnwo/hk8ON8Rxi9vRUNmVgw8WUsi+DnwF3d/KHq/BBjp7qvr2qYSQf0++CDc5XDXXaEI6YAD4PzzQ1cWffrkOzppSt56K5xYTJu2666Wli3D7ZM9e6YfevQICSMXdu4Md/OsWhWG1at3f60aX70aKivDOp/6VDj4n3lmKKZNikJNBE8CN7r7C9H754Cr3H2Po7yZTQQmAvTo0WPIinS1r7IH9/AchLvugsceC/8IffvCpz8No0aFW9Patct3lFJo1q2D3/0uHPz//vcw7dhjQ/9YrVqFmx9Sh5Ur97wD7sAD0yeIffYJv8PKylCGnvqablrqvMpKqKjY84BfdYBPdcAB4crlkEPg4IN3jX/603D44fHvw0JUqIngj8CPaiSCb7v73Lq2qSuCvbN6dTize+aZ0Ex927Zw19HRR4d/jk9/GsrK1D4hqbZuhSefDAf/p54Kd6j16xduPhg3LhzIa1NZGYpdaiaIquHtt8PvLRsOOGD3A3u68YMOyt0VSVNSqIlARUN5sm1bONN75pnQWrKqG4tOncKtbFWJoTGtGKXw7dgBf/1ruGvmkUdg48ZwID3nnFB2PnBgdu5scYf33gv30FdWhquKli3Da23jtU1roU5x9lqhJoKTga+wq7J4qrsPrW+bSgTZV1EBzz0XksKzz4Z/WAiJYNSokBSOPx46dsxvnEmyfTu8/37426xdG4b33w+V/h067Dnsv3/mFbgLF4Yz/wcfDGfy7duHfq0mTAgNm3RV2DzlJRGY2UPASKALsAb4HlAE4O53m5kBdwAnAVuAC9LVD9SkRBAv91DBXJUUZs4MLZtbtIBBg8JBp2XLXWdnqa/ppqXOKyoKyaVv3zD06JGcM7xt20JZetWBPfUAXzWkTlu/vuGf0bZt+iRRNbRqFYp/Xn01jI8eHQ7+p5yiu8qSQA3KZK9t3w6zZ4dipH/+MxzQduwIlYM7duw+XvO15rStW3e1rIRwx8bhh+9qil819OkTKhWbip07Q9HH22/vGt55Z/f3772Xft1994WuXaFLl11DzfdVwwEHhP2/YcOew/r16aenDtu2hTqhCRPCLcVduuR2P0l+KRFIwVi7NrSyrAVMw6cAAAzFSURBVDmk9tfSsiV8/OO7J4e+fUNXvC1bhuSUOlRWZj4NdpV7m+0aMnm/c2eodK95wH/nHfjvf3f/nm3bhgrWQw8NVz49eoTxj31s94N727a5a2G6Y4eKfZJMiUAK3ubNoUiqqjl+1bB0afrbA/OpRQvo1m33A3zVeNXQsaP6fpLCUlciaGLtA5OpvByuuSacgfboAZMnN66fokLUrh0MGRKGVNu3hye4LV4cXiGUbxcV7T5kMi21MjV0LLCrZ9hM3puFWxObYstakbro51zganZat2JFeA/NLxmkU1S0qxtfEYlHQu7ZaLquuWb3nkshvL/mmvzEIyLNjxJBgUutRM1kuohIQykRFLgePRo2XUSkoZQICtzkyXv2kNimTZguIpINSgQFbvz48DSznj3DXSs9ezb+6WYiIql011ATMH68DvwiEh9dEYiIJJwSgYhIwikRiIgknBKBiEjCKRGIiCScEkEClJdDcXHoNbO4OLwXEami20ebuaR3Wici9dMVQTOnTutEpD5KBM2cOq0TkfooETRz6rROROqjRNDMqdM6EamPEkEzp07rRKQ+umsoAdRpnYjURVcEIiIJp0QgIpJwSgSSEbVOFmm+VEcg9VLrZJHmTVcEUi+1ThZp3pQIpF5qnSzSvCkRSL3UOlmkeYs1EZjZSWa2xMyWmdmkNPPPN7MKM5sfDRfFGY/sHbVOFmneYksEZtYSuBMYDfQDxplZvzSLPuzug6LhF3HFI3tPrZNFmrc47xoaCixz9zcBzGw6cBrwWoyfKTFR62SR5ivOoqFuwDsp71dG02r6nJktNLNHzOzQdBsys4lmNsfM5lRUVMQRq4hIYsWZCCzNNK/x/g9AsbuXAH8GfpVuQ+5+j7uXuXtZ165dsxym5IIapIkUrjgTwUog9Qy/O7AqdQF3X+fuH0Vv7wWGxBiP5ElVg7QVK8B9V4M0JQORwhBnIngJ6GNmvcxsH2As8ETqAmZ2cMrbU4HFMcYjeaIGaSKFLbbKYnevNLOvAE8DLYH73H2Rmd0AzHH3J4CvmdmpQCXwPnB+XPFI/qhBmkhhM/eaxfaFrayszOfMmZPvMKQBiotDcVBNPXvC8uW5jkYkmcxsrruXpZunlsUSOzVIEylsSgQSu2w0SNNdRyLxUTfUkhONaZCmbrBF4qUrAil4uutIJF5KBFLwdNeRSLyUCKTgqRtskXgpEUjBy8ZdR6psFqmdEoEUvMbedaQuLkTqpgZl0uypQZuIGpRJwmWjsllFS9KcKRFIs9fYymYVLUlzp0QgzV5jK5vVjkGaOyUCafYaW9msdgzS3CkRSCKMHx8qhnfuDK8N6ZoiG+0YVMcghUyJQKQejS1aykYdgxKJxEmJQKQejS1aamwdgyqrJW5KBCIZaEzRUmPrGLJRWa0rCqmLEoFIzBpbx9DYRKKiKamPEoFIzBpbx9DYRFIIRVNKJIVNiUAkZo2tY2hsIsl30ZQSSRPg7k1qGDJkiIskzbRp7j17upuF12nTMl+3Z0/3cAjefejZM7P1zdKvb5abz582zb1Nm93XbdOmYfugMfuvENbPBmCO13JczfuBvaGDEoFIwzT2QJr0RJLv9au20dhEokQgknCNOZAkPZHke/1sJBL3uhOBuqEWkXqVl4c6gbffDpXUkyc3/HkQqfUMbdpkXk/S2G7EW7QIh8+azMLtwIW+fra6UVc31CLSKI1pR5HvyvLG3nWV7/Vz0deVEoGIxK4pJ5J8r5+TZ3bXVmZUqIPqCESkofJ9108+62iqoDoCEZGmqzF1NFXqqiNolY0gRUQkPuPHN/zA3xCx1hGY2UlmtsTMlpnZpDTz9zWzh6P5s82sOM54RERkT7ElAjNrCdwJjAb6AePMrF+NxS4EPnD3w4DbgJviikdERNKL84pgKLDM3d909/8C04HTaixzGvCraPwR4AQzsxhjEhGRGuJMBN2Ad1Ler4ympV3G3SuBDUDnmhsys4lmNsfM5lRUVMQUrohIMsWZCNKd2de8RSmTZXD3e9y9zN3LunbtmpXgREQkiPOuoZXAoSnvuwOrallmpZm1AjoA79e10blz5641szQNrgtCF2BtvoOoQ6HHB4Ufo+JrHMXXOI2Jr2dtM+JMBC8BfcysF/AuMBY4p8YyTwBfAP4JnAk87/U0bHD3gr0kMLM5td2nWwgKPT4o/BgVX+MovsaJK77YEoG7V5rZV4CngZbAfe6+yMxuILRwewL4JfAbM1tGuBIYG1c8IiKSXqwNytx9BjCjxrTrUsa3AZ+PMwYREambOp3LrnvyHUA9Cj0+KPwYFV/jKL7GiSW+JtfXkIiIZJeuCEREEk6JQEQk4ZQIGsjMDjWzmWa22MwWmdnlaZYZaWYbzGx+NFyXblsxxrjczF6JPnuPPrstmBp19rfQzEpzGNvhKftlvpltNLMraiyT8/1nZveZ2Xtm9mrKtAPM7FkzWxq9dqpl3S9Eyyw1sy/kML4fm9nr0d/wMTPrWMu6df4eYozvejN7N+XvOKaWdevsnDLG+B5OiW25mc2vZd1Y919tx5Sc/v5qe1CBhvQDcDBQGo23B/4N9KuxzEjgyTzGuBzoUsf8McBThJbdw4DZeYqzJfAfoGe+9x9wLFAKvJoy7WZgUjQ+CbgpzXoHAG9Gr52i8U45im8U0CoavyldfJn8HmKM73rgmxn8Bt4AegP7AAtq/j/FFV+N+T8BrsvH/qvtmJLL35+uCBrI3Ve7+7xofBOwmD37UCp0pwG/9uBfQEczOzgPcZwAvOHueW8p7u6z2LNVe2qniL8CPptm1f8BnnX39939A+BZ4KRcxOfuz3joowvgX4TW+3lRy/7LRCadUzZaXfFFHV2eBTyU7c/NRB3HlJz9/pQIGiF6fsJgYHaa2Ueb2QIze8rM+uc0sNBf0zNmNtfMJqaZn0mHgLkwltr/+fK5/6p8zN1XQ/hnBQ5Ms0yh7MsvEq7y0qnv9xCnr0RFV/fVUrRRCPvvU8Aad19ay/yc7b8ax5Sc/f6UCPaSmbUDHgWucPeNNWbPIxR3DARuBx7PcXjHuHsp4VkQl5nZsTXmZ9TZX5zMbB/gVOB3aWbne/81RCHsy2uASqC8lkXq+z3E5S7g48AgYDWh+KWmvO8/YBx1Xw3kZP/Vc0ypdbU00xq8/5QI9oKZFRH+YOXu/n8157v7RnffHI3PAIrMrEuu4nP3VdHre8BjhMvvVJl0CBi30cA8d19Tc0a+91+KNVVFZtHre2mWyeu+jCoHPwOM96jQuKYMfg+xcPc17r7D3XcC99byufnef62AM4CHa1smF/uvlmNKzn5/SgQNFJUn/hJY7O631rLMQdFymNlQwn5el6P42ppZ+6pxQoXiqzUWewI4L7p7aBiwoeoSNIdqPQvL5/6roapTRKLX36dZ5mlglJl1ioo+RkXTYmdmJwFXAae6+5Zalsnk9xBXfKn1TqfX8rnVnVNGV4ljCfs9V04EXnf3lelm5mL/1XFMyd3vL66a8OY6AMMJl14LgfnRMAa4BLgkWuYrwCLCHRD/Aj6Zw/h6R5+7IIrhmmh6anxGeIzoG8ArQFmO92EbwoG9Q8q0vO4/QlJaDWwnnGVdSHhI0nPA0uj1gGjZMuAXKet+EVgWDRfkML5lhPLhqt/h3dGyhwAz6vo95Ci+30S/r4WEg9rBNeOL3o8h3CnzRi7ji6Y/UPW7S1k2p/uvjmNKzn5/6mJCRCThVDQkIpJwSgQiIgmnRCAiknBKBCIiCadEICKScEoEIhEz22G794yatZ4wzaw4tedLkUIS6zOLRZqYre4+KN9BiOSarghE6hH1R3+Tmb0YDYdF03ua2XNRp2rPmVmPaPrHLDwfYEE0fDLaVEszuzfqc/4ZM9svWv5rZvZatJ3pefqakmBKBCK77FejaOjslHkb3X0ocAcwJZp2B6E77xJCh29To+lTgb966DSvlNAiFaAPcKe79wfWA5+Lpk8CBkfbuSSuLydSG7UsFomY2WZ3b5dm+nLgeHd/M+oc7D/u3tnM1hK6TdgeTV/t7l3MrALo7u4fpWyjmNBvfJ/o/VVAkbv/wMz+BGwm9LL6uEcd7onkiq4IRDLjtYzXtkw6H6WM72BXHd3JhL6fhgBzox4xRXJGiUAkM2envP4zGv8HobdMgPHAC9H4c8ClAGbW0sz2r22jZtYCONTdZwLfBjoCe1yViMRJZx4iu+xnuz/A/E/uXnUL6b5mNptw8jQumvY14D4z+xZQAVwQTb8cuMfMLiSc+V9K6PkynZbANDPrQOgV9jZ3X5+1bySSAdURiNQjqiMoc/e1+Y5FJA4qGhIRSThdEYiIJJyuCEREEk6JQEQk4ZQIREQSTolARCThlAhERBLu/wP+MhLY80kWEAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es scheint, dass das Netzwerk nach 8 Epochen zu overfitten beginnt. Lassen Sie uns ein neues Netzwerk von Grund auf für 8 Epochen trainieren und es dann auf dem Testset auswerten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 2.6768 - accuracy: 0.5396 - val_loss: 1.7884 - val_accuracy: 0.6460\n",
      "Epoch 2/8\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 1.4402 - accuracy: 0.7081 - val_loss: 1.3162 - val_accuracy: 0.7220\n",
      "Epoch 3/8\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 1.0661 - accuracy: 0.7775 - val_loss: 1.1744 - val_accuracy: 0.7380\n",
      "Epoch 4/8\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.8451 - accuracy: 0.8222 - val_loss: 1.0454 - val_accuracy: 0.7930\n",
      "Epoch 5/8\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.6780 - accuracy: 0.8594 - val_loss: 0.9652 - val_accuracy: 0.7990\n",
      "Epoch 6/8\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.5493 - accuracy: 0.8866 - val_loss: 0.9554 - val_accuracy: 0.8100\n",
      "Epoch 7/8\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.4432 - accuracy: 0.9093 - val_loss: 0.8977 - val_accuracy: 0.8170\n",
      "Epoch 8/8\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.3594 - accuracy: 0.9248 - val_loss: 0.8967 - val_accuracy: 0.8180\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 0.9745 - accuracy: 0.7898\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=8,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9745488166809082, 0.7898486256599426]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unser Ansatz erreicht eine Genauigkeit von ~78%. Bei einem ausgeglichenen binären Klassifikationsproblem würde die Genauigkeit, die ein rein zufälliger Klassifikator erreicht, 50 % betragen, aber in unserem Fall liegt sie näher bei 19 %, sodass unsere Ergebnisse ziemlich gut erscheinen, zumindest im Vergleich zu einer zufälligen Basislinie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18432769367764915"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "test_labels_copy = copy.copy(test_labels)\n",
    "np.random.shuffle(test_labels_copy)\n",
    "float(np.sum(np.array(test_labels) == np.array(test_labels_copy))) / len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erzeugen von Vorhersagen für neue Daten\n",
    "\n",
    "Wir können überprüfen, dass die Vorhersagemethode unserer Modellinstanz eine Wahrscheinlichkeitsverteilung über alle 46 Themen liefert. Lassen Sie uns nun Themenvorhersagen für alle Testdaten generieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeder Eintrag in predictions ist ein Vektor der Länge 46:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Koeffizienten in diesem Vektor summieren sich zu 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000001"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der größte Eintrag ist die vorhergesagte Klasse, d. h. die Klasse mit der höchsten Wahrscheinlichkeit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eine andere Art, die Beschriftungen und den Verlust zu behandeln\n",
    "\n",
    "Wir haben bereits erwähnt, dass eine andere Möglichkeit, die Beschriftungen zu kodieren, darin bestünde, sie als Integer-Tensor zu kodieren, etwa so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Einzige, was sich dadurch ändern würde, ist die Wahl der Verlustfunktion. Unsere bisherige Verlustfunktion, categorical_crossentropy, erwartet, dass die Beschriftungen einer kategorialen Kodierung folgen. Bei ganzzahligen Beschriftungen sollten wir sparse_categorical_crossentropy verwenden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese neue Verlustfunktion ist mathematisch immer noch die gleiche wie categorical_crossentropy; sie hat nur eine andere Schnittstelle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Über die Bedeutung ausreichend großer Zwischenschichten\n",
    "\n",
    "Wir haben bereits erwähnt, dass wir, da unsere endgültigen Ausgaben 46-dimensional sind, Zwischenschichten mit viel weniger als 46 versteckten Einheiten vermeiden sollten. Nun wollen wir versuchen zu sehen, was passiert, wenn wir einen Informationsengpass einführen, indem wir Zwischenschichten mit deutlich weniger als 46-dimensionalen, z. B. 4-dimensionalen, haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 2.7669 - accuracy: 0.3449 - val_loss: 2.0567 - val_accuracy: 0.5630\n",
      "Epoch 2/20\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 1.7791 - accuracy: 0.5778 - val_loss: 1.6294 - val_accuracy: 0.5870\n",
      "Epoch 3/20\n",
      "63/63 [==============================] - 1s 20ms/step - loss: 1.4524 - accuracy: 0.6086 - val_loss: 1.4514 - val_accuracy: 0.6130\n",
      "Epoch 4/20\n",
      "63/63 [==============================] - 1s 18ms/step - loss: 1.2433 - accuracy: 0.6547 - val_loss: 1.3792 - val_accuracy: 0.6400\n",
      "Epoch 5/20\n",
      "63/63 [==============================] - 1s 20ms/step - loss: 1.0901 - accuracy: 0.7001 - val_loss: 1.3293 - val_accuracy: 0.6690\n",
      "Epoch 6/20\n",
      "63/63 [==============================] - 1s 20ms/step - loss: 0.9769 - accuracy: 0.7414 - val_loss: 1.3054 - val_accuracy: 0.6860\n",
      "Epoch 7/20\n",
      "63/63 [==============================] - 1s 20ms/step - loss: 0.8855 - accuracy: 0.7730 - val_loss: 1.2765 - val_accuracy: 0.7000\n",
      "Epoch 8/20\n",
      "63/63 [==============================] - 1s 18ms/step - loss: 0.8095 - accuracy: 0.7925 - val_loss: 1.3033 - val_accuracy: 0.7050\n",
      "Epoch 9/20\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.7434 - accuracy: 0.8106 - val_loss: 1.3077 - val_accuracy: 0.7000\n",
      "Epoch 10/20\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.6876 - accuracy: 0.8245 - val_loss: 1.3171 - val_accuracy: 0.7080\n",
      "Epoch 11/20\n",
      "63/63 [==============================] - 1s 18ms/step - loss: 0.6358 - accuracy: 0.8408 - val_loss: 1.3717 - val_accuracy: 0.7090\n",
      "Epoch 12/20\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 0.5936 - accuracy: 0.8508 - val_loss: 1.3874 - val_accuracy: 0.7120\n",
      "Epoch 13/20\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 0.5543 - accuracy: 0.8584 - val_loss: 1.4378 - val_accuracy: 0.7140\n",
      "Epoch 14/20\n",
      "63/63 [==============================] - 1s 18ms/step - loss: 0.5246 - accuracy: 0.8675 - val_loss: 1.4550 - val_accuracy: 0.7210\n",
      "Epoch 15/20\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.4923 - accuracy: 0.8720 - val_loss: 1.5413 - val_accuracy: 0.7180\n",
      "Epoch 16/20\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.4692 - accuracy: 0.8775 - val_loss: 1.5489 - val_accuracy: 0.7200\n",
      "Epoch 17/20\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 0.4456 - accuracy: 0.8835 - val_loss: 1.6163 - val_accuracy: 0.7280\n",
      "Epoch 18/20\n",
      "63/63 [==============================] - 1s 18ms/step - loss: 0.4273 - accuracy: 0.8891 - val_loss: 1.6177 - val_accuracy: 0.7250\n",
      "Epoch 19/20\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 0.4099 - accuracy: 0.8916 - val_loss: 1.6976 - val_accuracy: 0.7210\n",
      "Epoch 20/20\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.3938 - accuracy: 0.8938 - val_loss: 1.7551 - val_accuracy: 0.7270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fcad8e0648>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(4, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unser Netzwerk scheint jetzt bei ~71% Testgenauigkeit zu liegen, ein absoluter Abfall von 8%. Dieser Rückgang ist hauptsächlich darauf zurückzuführen, dass wir jetzt versuchen, eine Menge Informationen (genug Informationen, um die Trennungshyperflächen von 46 Klassen wiederherzustellen) in einen Zwischenraum zu komprimieren, der zu niedrig-dimensional ist. Das Netzwerk ist in der Lage, die meisten der notwendigen Informationen in diese 8-dimensionalen Repräsentationen zu packen, aber nicht alle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weitere Experimente\n",
    "\n",
    "- Versuchen Sie, größere oder kleinere Layer zu verwenden: 32 Einheiten, 128 Einheiten...\n",
    "- Wir haben zwei versteckte Schichten verwendet. Versuchen Sie nun, eine einzelne versteckte Schicht oder drei versteckte Schichten zu verwenden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abschließende Betrachtung\n",
    "\n",
    "Folgendes sollten Sie aus diesem Beispiel mitnehmen:\n",
    "\n",
    "- Wenn Sie versuchen, Datenpunkte zwischen N Klassen zu klassifizieren, sollte Ihr Netzwerk mit einer Dense-Schicht der Größe N enden.\n",
    "\n",
    "- Bei einem Ein-Label-Mehrklassen-Klassifikationsproblem sollte Ihr Netzwerk mit einer Softmax-Aktivierung enden, so dass es eine Wahrscheinlichkeitsverteilung über die N Ausgabeklassen ausgibt.\n",
    "- Die kategoriale Kreuzentropie ist fast immer die Verlustfunktion, die Sie für solche Probleme verwenden sollten. Sie minimiert den Abstand zwischen den Wahrscheinlichkeitsverteilungen, die vom Netz ausgegeben werden, und der wahren Verteilung der Ziele.\n",
    "- Es gibt zwei Möglichkeiten, Beschriftungen in der Mehrklassen-Klassifikation zu behandeln: Kodierung der Beschriftungen über \"kategorische Kodierung\" (auch als \"One-Hot-Kodierung\" bekannt) und Verwendung von \"categorical_crossentropy\" als Ihre Verlustfunktion. Kodierung der Beschriftungen als Ganzzahlen und Verwendung der Verlustfunktion \"sparse_categorical_crossentropy\".\n",
    "- Wenn Sie Daten in eine große Anzahl von Kategorien klassifizieren müssen, dann sollten Sie es vermeiden, durch zu kleine Zwischenschichten Informationsengpässe in Ihrem Netzwerk zu erzeugen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
